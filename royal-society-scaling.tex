% Use only LaTeX2e, calling the article.cls class and 12-point type.

\documentclass[12pt]{article}

% Users of the {thebibliography} environment or BibTeX should use the
% scicite.sty package, downloadable from *Science* at
% www.sciencemag.org/about/authors/prep/TeX_help/ .
% This package should properly format in-text
% reference calls and reference-list numbers.

%\usepackage{scicite}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{amsmath,array,mathtools}
\usepackage{color,soul}
\usepackage[toc,page]{appendix}
\usepackage[symbol]{footmisc}

% Use times if you have the font installed; otherwise, comment out the
% following line.

\usepackage{times}

% The preamble here sets up a lot of new/revised commands and
% environments.  It's annoying, but please do *not* try to strip these
% out into a separate .sty file (which could lead to the loss of some
% information when we convert the file to other formats).  Instead, keep
% them in the preamble of your main LaTeX source file.


% The following parameters seem to provide a reasonable page setup.

\topmargin 0.0cm
\oddsidemargin 0.2cm
\textwidth 16cm 
\textheight 21cm
\footskip 1.0cm


%The next command sets up an environment for the abstract to your paper.

\newenvironment{sciabstract}{%
\begin{quote} \bf}
{\end{quote}}


% If your reference list includes text notes as well as references,
% include the following line; otherwise, comment it out.

\renewcommand\refname{References and Notes}

% The following lines set up an environment for the last note in the
% reference list, which commonly includes acknowledgments of funding,
% help, etc.  It's intended for users of BibTeX or the {thebibliography}
% environment.  Users who are hand-coding their references at the end
% using a list environment such as {enumerate} can simply add another
% item at the end, and it will be numbered automatically.

\newcounter{lastnote}
\newenvironment{scilastnote}{%
\setcounter{lastnote}{\value{enumiv}}%
\addtocounter{lastnote}{+1}%
\begin{list}%
{\arabic{lastnote}.}
{\setlength{\leftmargin}{.22in}}
{\setlength{\labelsep}{.5em}}}
{\end{list}}


% Include your paper's title here

\title{Biological and Computer Designs Minimize Energy and Time. NOTE change title and abstract for Roy Soc} 

% Place the author information here.  Please hand-code the contact
% information and notecalls; do *not* use \footnote commands.  Let the
% author contact information appear immediately below the author names
% as shown.  We would also prefer that you don't change the type-size
% settings shown here.

\author
{George Bezerra,$^{1,2\ast}$  James Brown,$^{3}$ Melanie 
Moses,$^{2,3}$ Stephanie Forrest$^{2}$\\
\\
\normalsize{$^{1}$Computer Science and Artificial Intelligence 
Laboratory}\\
\normalsize{Massachusetts Institute of Technology, Cambridge, MA, 
USA.}\\
\normalsize{$^{2}$Department of Computer Science}\\
\normalsize{University of New Mexico, Albuquerque, NM, USA.}\\
\normalsize{$^{3}$Department of Biology}\\
\normalsize{The University of New Mexico, Albuquerque, NM, USA.}\\
\\
\normalsize{$^\ast$To whom correspondence should be addressed}\\
\normalsize{E-mail: gbezerra@csail.mit.edu}\\
\normalsize{Address: The Sata Center Building 32-G778}\\
\normalsize{32 Vassar Street, Cambridge, Massachusetts 02139 USA}\\
\normalsize{Phone: 617-324-8434}\\
}



% Include the date command, but leave its argument blank.

\date{\normalsize{{\bf Keywords:} network scaling, power consumption, 
metabolic rate, complex systems, energy-time product, organism, 
computer chip}\\
\normalsize{{\bf Classification:} Major: ; Minor: }}



%%%%%%%%%%%%%%%%% END OF PREAMBLE %%%%%%%%%%%%%%%%



\begin{document} 

\newcounter{casenum}
\newenvironment{caseof}{\setcounter{casenum}{1}}{\vskip.5\baselineskip}
\newcommand{\case}[2]{\vskip.5\baselineskip\par\noindent {\bfseries Case \arabic{casenum}:} #1\\#2\addtocounter{casenum}{1}}

% Double-space the manuscript.

\baselineskip24pt

% Make the title.

\maketitle 


\newpage

% Place your abstract within the special {sciabstract} environment.
% \centerline{\Large{\bf Abstract}}
% \begin{sciabstract}
% Metabolic rate in organisms and power consumption in computers are 
% analogous quantities that scale similarly with size.  We analyze 
% organisms and computer chips as systems in which natural selection or 
% human engineering has produced optimized networks that minimize the 
% energy-time product.  The network designs simultaneously reduce energy 
% costs and increase flow rates.  Using a simple network model, our 
% analysis explains empirically observed trends in the scaling of 
% metabolic rate in organisms and power consumption in chips across 
% several orders of magnitude in size.  This result suggests that a 
% single principle governs the designs of many complex systems that 
% process energy, materials, and information.
% \end{sciabstract}

% Place your abstract within the special {sciabstract} environment.
% The new abstract
\centerline{\Large{\bf Abstract}}
\begin{sciabstract}
  Metabolic rate in animals and power consumption in computers are
  analogous quantities that scale similarly with size.  We analyze
  vascular systems of vertebrates and on-chip networks of
  microprocessors, where natural selection and human engineering
  respectively have produced optimized networks.  
% 'modeled  here as the energy-time product'?
Both network designs
  simultaneously reduce energy costs and increase flow rates.  Using a
  simple network model, our analysis explains empirically observed
  trends in the scaling of metabolic rate in organisms and power
  consumption in chips across several orders of magnitude in size.
  This result suggests that a single principle governs the designs of
  complex systems that process energy, materials, and
  information.
\end{sciabstract}

\newpage

\section{Introduction}
\label{sec:intro}

Both organisms and computers have evolved from relatively simple 
beginnings into complex systems that vary by orders of magnitude in 
size and number of components. Evolution, by natural selection in 
organisms and by human engineering in computers, required critical 
features of architecture and function to be scaled up as size and 
complexity increased. In Biology, Kleiber's law describes the
empirical relation between 
metabolic rate and many other traits, such as lifespan, heart rate, 
and number of offspring, with body size \cite{kleiber47}.  
Similarly, computer architecture has Moore's law to describe scaling of transistor density and 
performance \cite{moore98}, Koomey's law for the energy cost per 
computation \cite{koomey11}, and Rent's rule for the external 
communication per logic block \cite{christie00}.

% We posit that these empirical patterns originate from a common 
% principle: Networks that deliver resources are optimized to reduce 
% energy dissipation and increase flow rates, expressed here as 
% minimizing the energy-time product. {\bf Need to clarify where energy
%   is disipated.  we ention energy-time product but rest of paragraph
%   is about the network and not the nodes.}  In biology, the vascular network 
% of vertebrate animals supplies oxygen and nutrients to every cell, 
% fueling metabolism for maintenance, growth and reproduction.  Since 
% energy is a limited resource, organisms are selected to minimize the 
% energy dissipated in the network \cite{west97}. Similarly, computation 
% in microprocessors relies on a network of microscopic wires that 
% transmits bits of information between transistors on a chip.  In order 
% to maximize computer performance and minimize power consumption, this 
% network is designed to deliver the maximum information flow at the 
% lowest possible energy cost.

We posit that these empirical patterns originate from a common 
principle: Networks that deliver resources are optimized to reduce 
energy dissipation and increase flow rates, expressed here as 
minimizing the energy-time product. That is, both living systems and
computer chips are designed
to maximize the rate at which resources are delivered to terminal
nodes of a network and to minimize the energy cost in the network.
In biology, the vascular network 
of vertebrate animals supplies oxygen and nutrients to every cell, 
fueling metabolism for maintenance, growth and reproduction.  Since 
energy is a limited resource, we assume that organisms are selected to minimize the 
energy dissipated in the network \cite{west97}. Similarly, computation 
in microprocessors relies on a network of microscopic wires that 
transmits bits of information between transistors on a chip.  In order 
to maximize computation speed and minimize power consumption, this 
network is designed to deliver the maximum information flow at the 
lowest possible energy cost.

Here, we model vertebrates as composed of regions of tissue that 
receive oxygen carried by blood via a hierarchical vascular network of pipes, and we 
model microprocessors as composed of transistors that perform 
computation, exchanging information over a modular network of wires.  
As each system scales up in size, we consider: 1) the rate at which 
resources are delivered by the network and processed in the nodes; 
and 2) the energy dissipated during these processes. Despite the 
obvious differences between organisms and chips, we present a general
model and derive 
energy and time scaling relations from physical principles applicable 
to each system. Using these relations, we express the optimal network 
design as a tradeoff between energy cost and processing speed. 

% Here, we model vertebrates as composed of regions of tissue that 
% receive blood via a hierarchical vascular network of pipes, and we 
% model microprocessors as composed of transistors that perform 
% computation, exchanging information over a modular network of wires.  
% As each system scales up in size, we consider: 1) the time for 
% resources to flow through the network and be processed in the nodes; 
% and 2) the energy dissipated during these processes. Despite the 
% obvious differences between organisms and chips, we derive general 
% energy and time scaling relations from physical principles applicable 
% to each system. Using these relations, we express the optimal network 
% design as an energy-time product minimization problem.

Earlier models in biology have assumed either energy minimization, e.g.,
\cite{west97} or optimal resource delivery rate \cite{banavar10}, but they have
not formalized the tradeoffs between them, as we do here.  This formalization
helps explain how  nature and engineering are able to produce designs that
approach pareto-optimal along the energy-time tradeoff.  Thus, in biology
evolution has produced mammals ranging in size from mice to elephants, rather
than converging on a single optimal size, and in computer architecture
engineers have designed processors ranging from a few thousand transistors to
several billion, each of which fills a specific computational niche.

In the rest of the paper, we first present the unified model of network scaling
(Sec.~\ref{sec:unified-model} and the basic assumptions underlying the model
(Sec.~\ref{sec:assumptions}.  We discuss predictions of the model, first for
organisms (Sec.~\ref{sec:organisms}) and then for computers
(Sec.~\ref{sec:computers}). [SAY HERE WHAT WE PREDICT].  Finally, in
Sec.~\ref{sec:discussion}  we discuss the implications of these results for
evolutionary transitions in nature and engineering.

[MAKE A FIGURE HERE.LIKE GEORGE'S DISSERTATION]

\section{A Unified Model of Network Scaling}
\label{sec:unified-model}


Vascular systems are hierarchical branching networks where blood vessels
(pipes) become thicker and longer as hierarchy increases from the capillaries
to the aorta. Similarly, microprocessor chips are organized hierarchically into
a nested structure of modules and submodules, where wires become longer and
thicker as the hierarchical level of a module increases
(Figure~\ref{fig:model-schematic}).  These wires are organized into metal
layers, where short, thin wires are routed on the lowest layers, and long,
thick wires are placed on the top layers. We model the scaling of length ($l$)
and thickness ($r$) of both pipes and wires as

\begin{equation}
l_i = l_0 \lambda^{i/D_l}
\end{equation}

\noindent and

\begin{equation}
r_i = r_0 \lambda^{i/D_r},
\label{eq:rscaling}
\end{equation}

\noindent where $i$ is the hierarchical level of a branch or module, $\lambda$
is the branching factor, and $D_l$ and $D_r$ are the length and thickness
dimensions. This model is akin to the hierarchical pipe model of vascular
systems proposed in \cite{west97}, $\lambda^{1/Dr}$ and$\lambda^{1/Dl}$
correspond to West et al.'s $\beta$ and $\gamma$ respectively.
% where $l_i$ ROUGHLY corresponds to $\gamma$
%and $r_i$ ROUGHLY corresponds to $\beta$.  
In vascular networks, $r$ represents the radius of cylindrical pipes, and in
computer interconnects, $r$ represents the width of wires with aspect ratio 1.
The smallest edges occur at $i = 0$, and have constant length and thickness,
$l_0$ and $r_0$. 

\begin{figure}
\caption{Schematic: Panel c illustrates the communication dimension, $D_w$,
  which measures how the ratio of internal (intra-module) communication per node to
  external (inter-module) communication per node scales with the level of the module in
  the hierarchy. Note, that if we had a biological version, we would
  have MORE edges.}
  \label{fig:model-schematic}
\end{figure}

The length parameter $D_l$ determines the spatial dimension occupied 
by the nodes of the network \cite{mandelbrot83}.
%and is an independent 
%variable in the above formulation.  
dimensions.  For chips, $D_l = 2$, since transistors are placed on a 
single two-dimensional layer \cite{donath81}.

Digital circuits scale in a third way in addition to length and
radius, which has no direct 
analog in organisms. Although vascular networks have a single pipe per 
branch, chips have multiple wires per module, and their number 
increases with the hierarchical level. This difference arises from the 
fact that digital circuits are decentralized networks connecting 
multiple sources and destinations, while vascular networks are 
centralized, with blood flowing from a single heart. To account for 
this difference, we introduce a new equation, in which the 
communication (or number of wires) per module increases with the 
hierarchical level as

\begin{equation}
w_i = w_0 \lambda^{i/D_w},
\label{eq:communication}
\end{equation}

\noindent where $D_w$ is the communication dimension and $w_0$ is the average
number of wires per node.  This hierarchical scaling of communication is a
well-known pattern in circuit design called Rent's rule \cite{christie00},
where $p = 1/D_w$ is the Rent's exponent.\footnote{Rent's rule is typically
  expressed as $C(n) = kn^p$, where $C_n$ is the external communication of a
  module, $n$ is the size of the module (number of nodes), $k$ is the average
  external communication of a module with size 1, and $p$ is the Rent’s
  exponent. For a hierarchy with branching factor of $\lambda$, the size of a
  module is given as $n = \lambda^i$, where $i$ is the hierarchical level.
  Therefore, we can rewrite Rent’s rule as $c_i = c_0 \times \lambda^{ip}$,
where $c_0 = w_0$ and $p = 1 / D_w$.} This pattern is not unique to circuits
and has been shown to occur in many biological networks
\cite{reda09,bassett10}.   Vascular systems correspond to a special case where 
%$w_0 = 1$ and $1/D_w = 0$, such that 
$w_i = 1$ for all $i$. 

\subsection{Assumptions of the Unified Model}
\label{sec:assumptions}

Before deriving scaling predictions from the model, we make explicit
its  assumptions and how they relate to earlier models, both in
computation and biology:

\begin{enumerate}
\item {\bf Time and energy are equally important constraints:} 
  System designs seek to deliver the maximum amount of
  resource per unit time for the minimum amount of energy overhead. 
%interpreted as minimizing the energy dissipated to deliver
%  and process a unit of resource, while simultaneously minimizing the
%  time to deliver and process that resource.  
  In computer architecture this relationship is expressed as the
  \emph{energy-delay product}, which formalizes the insight that a
  chip that is ten times faster or ten times more energy efficient is
  ten times better. 
%It is
%unrealistic that either of these quantities is minimized independently
%of the other.
%WHY ISN'T IT ADDITIVE?
% A multiplicative decrease of either quantity should be reflected
% proportionally by the energy-delay equation.  i.e., a chip that is
% 10 times faster, should make the energy-delay equation 10 times
% better.  Has something to do with multiplicity of components.

\item {\bf Steady state}: Resource supply matches processing
  demand~\cite{banavar10}.  That is, the network supplies
  resources continually to the terminal nodes and is
  always filled to capacity.  This avoids network delays and the need to
  store resources in the system. Specifically,
\begin{enumerate}
\item System designs balance network delivery rates with node
  processing speeds, so that resources are delivered at exactly the
  same rate that they are processed.

\item Pipelining: A concept from computer architecture in which
  resources, e.g., computer instructions, leave the source at
  the same rate that they are delivered to the terminal nodes, and the
  network is always full.  In the hierarchical networks considered
  here, the source is the highest branch (root), and the
  principle holds within every level of the hierarchy.  Consequently,
  resources flow through the network continually at maximum speed, and
  they do not accumulate at source, sink, or
  intermediate locations.
\end{enumerate}

\item {\bf Terminal units and service volumes:} In contrast to Ref.~\cite{west97} we
  do not assume that terminal units have
  fixed size.   In chips it is well known that transistor size has
  shrunk over many orders of magnitude.   Previous scaling models of
  biology posit that the service volume (region served by terminal units of the network) actually increases with system
  size~\cite{west97,banavar10}.  Folowing Ref.~\cite{banavar10}, we assume that
  capillaries have fixed radius but that their length is proportional to the
  radius of the service volume.   Similarly, the radius of the isochronic region
  (service volume) for chips scales proportionally with decreasing
  transistor size.
% really we mean 'length' of one side of the transistor, aka process size.
\end{enumerate}

In addition to these general assumptions, we make the following
refinements to accommodate salient differences between biology and computer architecture.
\begin{enumerate}
\item In biology, the energy processed by a service volume,
  $E_{node}$, is invariant with system size.\footnote{IS $E_{NODE}$ THE METABOLIC OUTPUT (MAXIMIZE) OR COST OF METABOLISM
  (MINIMIZE)?}  That is, as the service volume
  increases with body size, the total amount of energy processed
  remains constant.   We do not make this assumption for chips.

\item Component packing: In chips, we assume that total chip area is constant, and the
  number of transistors $N$ is the square of the process size, i.e.,
  the length of one side of a transistor. 

\end{enumerate}



\section{Predictions of the Model for Organisms and Computers}
%\label{sec:}

We define $E_{net}$ and $T_{net}$ respectively to be the energy dissipated and
the time taken by the network to deliver a unit of resource to a node.  For
organisms the resource is oxygen (in mammals, carried by a unit volume of
blood), and for computers the fundamental resource is a bit of information.
Similarly, we define $E_{node}$ and $T_{node}$ as the energy dissipated and the
time taken by a node to process that resource.  For organisms, the node is the
service volume corresponding to a region of tissue supplied by a single
capillary, $E_{net}$ is the energy required to deliver oxygen to the cells (as
studied by \cite{west97}), and $E_{node}$ is the energy dissipated by cells
processing incoming oxygen.[BE: Is this oxygen or all nutriets?]. $T_{net}$ and
$T_{node}$ are the time delay between delivering new resources to the cell and
the time taken for the cell to process those resources respectively. The
pipelining and steady-state assumptions indicate that $T_{net} = T_{node}$,
i.e., supply matches demand in organisms.

For computers, the nodes are transistors, and 
%$E_{net}$ and $T_{net}$ correspond to the energy dissipated and the time taken
%to transport a bit of information to a node over the network, and 
$E_{net}$ and $E_{node}$ represent the energy dissipated delivering bits to
transistors and the energy required to process the bits at the node, and
$T_{net}$ and $T_{node}$ are the times required to deliver and process a bit at
the node (i.e., network and transistor switching delay).  In computers time
taken to deliver and process bits is bounded by the maximum of the
communication time $\max(T_{net},T_{node})$, i.e.\ a node cannot process
another bit until it is delivered, and a node cannot process a new bit until it
is done processing the previous bit. For both organisms and computers we define
the total energy as $E_{sys} = E_{net} + E_{node}$ and the total delay as
$T_{sys} = \max(T_{net},T_{node})$.

%Note, the service volume is not necessarily of fixed size~\cite{banavar10}.
In the following, we derive general scaling relationships between these
quantities and the number of nodes $N$, assuming that the energy time product
is minimized.  That is, system designs seek to deliver the maximum amount of
resource per unit time for the minimum amount of energy overhead.   This is
equivalent to minimizing the energy dissipated to deliver and process a unit of
resource, while simultaneously minimizing the time to deliver and process that
resource.  Assuming that time and energy are equally important, this quantity
becomes the energy-time product, a well-known concept in computer architecture
referred to as the energy-delay product.  

%For computers, the nodes are isochronic regions (the service area supplied by a
%single clock signal),
%%We hypothesize that both organisms and computers maximize performance and minimize cost through
%scaled designs, where performance is given by resource flow (the rate at which a resource is delivered to and processed by the node), and cost is given by energy
%dissipated in the network and by the nodes, normalized per unit of resource processed.

%The hypothesis that organisms and computers minimize the energy-time 
%product predicts that scaled designs lie in a critical region of the 
%design space with the highest performance per cost, where performance 
%is given by flow and cost by energy.  
%To show this mathematically, we 
%use the general scaling relations from Table \ref{tab:equations} and 
We express the optimal network design as a constraint optimization 
problem in which the whole system's energy-time product is minimized:

\begin{equation}
  \min_{D_r,D_l,D_w}(E_{sys} \times T_{sys})
\label{eq:TheWholeEnchilada}
\end{equation}

%\noindent where the system's energy is given as $E_{sys} = E_{net} + E_{node}$,
%and the system's time as $T_{sys} = \max(T_{net}, T_{node})$.

We derive expressions for $E_{sys}$ and $T_{sys}$ for organisms
(Sec.~\ref{sec:organisms}) and computers (Sec.~\ref{sec:computers}) in
terms of the dimensions $D_l$, $D_r$, and $D_w$.  

%The resulting scaling equations are summarized in Table \ref{tab:equations}.

% \begin{table}[!h]
% \caption{General energy and time scaling relations for organisms and 
% computers.  The relations are written as a function of the number of 
% nodes ($N$), which is a proxy for size, and the length and thickness 
% dimensions ($D_l$ and $D_r$), which determine network geometry. $c$ is a constant}

% \label{tab:equations}
% \centering
% \def\arraystretch{1.7}
% \begin{tabular}{|c|c|c|c||c|c|c|}\hline
%  & $E_{net} $ & $E_{node}$ & $E_{sys}$ & $T_{net}  $ & $T_{node}$ & $T_{sys}$\\ \hline

% Organism & $\propto N^{\frac{2}{D_r}-1}$ & $\propto N^0 \propto c$ &  $\propto N^{\frac{2}{D_r}-1} + c$ &
% $\propto N^{1 - \frac{2}{D_r}}$  & $\propto N^{1 - \frac{2}{D_r}}$ & $\propto N^{1 - \frac{2}{D_r}}$ \\ \hline

% Computer & $\propto N^{-\frac{1}{D_w}}$ & $\propto N^{-\frac{1}{D_l}}$ & $\propto N^{-\frac{1}{D_l}}$ & $\propto N^0$ & $\propto N^{-\frac{1}{D_l}}$ & $\propto N^0 + N^{\frac{1}{D_l}}$\\ \hline
% %Computer & $\propto N^{-\frac{1}{D_w}}$ & $\propto N^{-\frac{1}{D_l}} & $\propto N^{-\frac{1}{D_l}}$ & $\propto N^0$ & $\propto N^{-\frac{1}{D_l}}$  TSYS &  \\ \hline

% \end{tabular}
% \end{table}

\subsection{Organisms}
\label{sec:organisms}

In this section, we derive general energy and time scaling relations 
for the network and nodes, in organisms in order to minimize Eq. \ref{eq:TheWholeEnchilada}.  

From basic principles of hydraulics, the energy dissipated to transport a
constant volume of blood through the network ($E_{net}$) is given by the loss
in pressure from the aorta to the capillaries multiplied by the volume being
transported.  Pressure is the product between hydraulic resistance ($R$) and
flow ($Q$), so the loss in pressure $\Delta P = RQ$.  Thus $E_{net} \propto
\Delta P \propto RQ$.
%{\bf RQ is pressure not loss in pressure, so something is fishy with this
%argument.}
We assume that the quantity of energy dissipated to metabolize a fixed amount
of nutrients is independent of metabolic rate and, therefore, $E_{node}$ is
proportional to the number of nodes in the system.   
%We now determine the energy dissipated and the time taken to process a unit
%volume of blood at the nodes ($E_{node}$ and $T_{node}$), where a node is
%defined as region of tissue serviced by a single capillary.  Since the
%concentration of nutrients in the blood is invariant, metabolic rate of a node
%is proportional to the rate at which blood is delivered, $T_{node} \propto
%T_{net} \propto N^{1-2/D_r}$.

%Flow through a pipe is defined as $Q = u\pi r^2$, where $u$ the fluid 
%velocity. Assuming that blood has constant initial velocity, flow is 
%determined by the cross-sectional area of the aorta as $Q = u \pi 
%r_H^2 = u \pi r_0^2 \lambda^{2H/D_r}\propto N^{2/D_r}$.  
% ASSUMPTION THAT WE NEED LATER
%In this 
%equation, $D_r \geq 2$, since for capillaries of fixed cross-sectional 
%area, flow is at most linear with $N$. 
%Finally, for a constant volume 
%of blood, the energy dissipated in the network is proportional to 
%pressure.  

% MEL AND STEPH SUBSTITUTED Q FOR $\overline{Q}$ in the following equations.
Considering the time component, the time to deliver a constant volume of blood
($T_{net}$) to a node is given by the volume of blood being transported divided
by the flow ($Q$).  Since this volume is constant, $T_{net}\propto 1/Q$.  One
might ask why there is no distance term in the previous equation.  Because of
the steady-state assumption, $T_{net}$ is the time it takes to get the `next'
oxygen molecule from a capillary and not the time it takes a single molecule to
traverse the network.
% THAT IS, it is exactly 'clock speed'
 %\propto N^{\frac{-2}{D_r}}$.  $T_{net}\propto 1/\overline{Q} \propto
%N^{1-2/D_r}$.
%Pipelining also implies that $T_{node} = T_{net}$. We already said this
%Following \cite{banavar10}, we assume that 'supply equals demand,' which 

The energy-time product for organisms, Eq.~\ref{eq:TheWholeEnchilada}
becomes:
%\footnote{Because $l_0$ is not constant, we need to
%   point out that the $u$ terms cancel out.  NOT SURE HOW TO DO THAT
%   NOW.}

\begin{equation}
  \min_{D_r,D_l} (RQ + N) \times (\frac{1}{Q}) \propto R +
 \frac{N}{Q}.
\label{eq:bio-min}
\end{equation}

\noindent where $N$ is the number of terminal units.  

%{\bf Because of pipelining, we think we only need one 1/Q term here.  $T_{net} = T_{node} = T_{sys}$}

The resistance of a pipe is given by given by the well-known Hagen-Poiseuille's
equation, where $R$ at hierarchical level $i$ is $R_i = 8\mu l_i/\pi r_i^4$,
where $\mu$ is the viscosity constant.  The total network resistance $R$ is
given by \cite{west97}:

\begin{equation}
\label{eq:resistance}
R = \sum_{i=0}^H \frac{8\mu l_i}{\pi r_i^4}\frac{1}{n_i}
= \frac{8\mu l_0}{\pi r_0^4} \lambda^{-H}\sum_{i=0}^H \lambda^{i 
\left(\frac{1}{D_l} - \frac{4}{D_r} + 1 \right)}
\end{equation}

\noindent where there are $H+1$ hierarchical levels, and $n_i = \lambda^{H-i}$
is the total number of pipes at hierarchical level $i$.  

West et al.\ predict that $R$ and therefore $E_{net}$ are minimized by $D_r =
3$ in the lower part of the network,  where Eq.~\ref{eq:resistance} dominates.
However, this prediction does not account for delivery time, which slows
dramatically when $D_r = 3$.  NOTE: To understand how pulsitile flow affects
resistance in the upper part of the network, see \cite{west97}, which shows
that $D_r = 2$, i.e., the network is area preserving, in this region.

We derive upper and lower bounds for $D_r$ in the network given that the goal
is to minimize the energy-time product.  Recalling that $\lambda^{-H} = N^{-1}$
and that $D_l = 3$ for organisms, in the case where $D_r \leq 3$, the summation
in Eq.~\ref{eq:resistance} converges to a constant (or $\log(N)$ in the case of
$D_r=3$), and $R \propto N^{-1}$. As $D_r$ increases from 3 to 12, $R$
increases from $\propto N^{-1}$ to a $R \propto N^{\frac{1}{3} -
\frac{4}{D_r}}$.\footnote{We do not consider $D_r > 12$, in which case $R
\propto N^a$ for a positive constant $a$}. See Sec.~\ref{sec:AppendixOrg} for
details of the calculation.
%In the case where $ D_r = 12$, $R \propto N^0$.   When $ 3 < D_r <12$, $R$
%decreases as $N$ increases.

% ASSUMPTION THAT WE NEED LATER
%For large $H$, the above series diverges when $D_r \geq 4D_l/(1+D_l)$ 
%and converges when $D_r < 4D_l/(1+D_l)$.  Because energy is minimized 
%in the region with lowest resistance, we consider the case when the 
%series converges, resulting in $R \propto \lambda^{-H} = N^{-1}$, 
%where $N$ is the number of capillaries.

% WE ARE CALCULATING FLOW AT THE CAPILLARIES (ASSUMING IT IS CONSTANT AND
% THEN SUMMING UP TO GET FLOW AT THE AORTA.  intermediate term in the
% equation below is there only so we can get to the final form, which
% we put in the table.
% BTW: It is reasonable to assume that capillary size is constant
% because they can't be smaller than the size of a red blood cell.
Flow through a pipe is defined as $Q = u\pi r^2$, where $u$ is the fluid 
velocity. 
%Assuming that blood has constant initial velocity,
%Consequently, flow in the aorta is equal to the sum of flows
%across all the capillaries: 
Therefore, flow through the aorta equals
$Q = u_H \pi r_{H}^2$, and substituting from Eq.~\ref{eq:rscaling}, $Q = u_0 \pi r_0^2
\lambda^{2H/D_r} = u_0 \pi r_0^2N^{2/D_r} $. 

Assuming that $U_H$ is independent of $N$ and $Q$ is equal at all levels of the
network (steady state assumption) gives:
$ Q \propto  N^{2/D_r}$.  

%Because capillaries are assumed to have constant
%radius ($r_0$) and flow through each capillary has constant velocity
% ($u_0$),\footnote{The Banavar, 2010 paper makes a different assumption,
%   namely that velocity scales as the length of the capilary. We think
%   that this is not a major problem and would simply make Dr a little
%   bigger.} this implies that $Q \propto N$, the number of capillaries.
% Setting these two expressions for $Q$ equal, predicts that $D_r  = 2$.

%The
%steady-steady assumption posits that flow is equal at all levels of
%the network. 
% ASSUMPTION THAT WE NEED LATER
%In this 
%equation, $D_r \geq 2$, since for capillaries of fixed cross-sectional 
%area, flow is at most linear with $N$. 
%Finally, for a constant volume 
%of blood, the energy dissipated in the network is proportional to 
%pressure.  

%Combining terms, $E_{net} = RQ \propto N^{\frac{2}{D_r}-1}$ when $D_r < 3$ and approaches $N^{\frac{2}{D_r}}$ as $D_r$ increases from  3 to 12.

% WE HAVE A GOOD ALGEBRAIC EXPLANATION FOR WHY SETTING D_R LESS THAN 2
% DOESN'T HELP MINIMIZE RESISTANCE.  NEXT, WE NEED TO APPEAL TO THE
% STEADY-STATE SUPPLY/DEMAND ASSUMPTION TO SAY THAT MINIMIZING D_R IN
% ORDER TO MAXIMIZE FLOW (FINGER OVER THE HOSE POSSIBILITY) WOULD LEAD
% TO LARGE SERVICE VOLUMES AND SLOW DIFFUSION, WHICH BANAVAR HAS
% ADDRESSED IN 2010.

Having derived scaling values for $R$ and $Q$ we can determine how the energy
delay product~\ref{eq:TheWholeEnchilada} scales for two relevant cases of $D_r$.

\begin{caseof}

  \case{$2 \leq D_r \leq 3$}{In this case $E_{sys} \times T_{sys} \propto N^{-1} +
  N^{1-\frac{2}{D_r}} \propto N^{1-\frac{2}{D_r}}$. Here B}

  \case{$3 \leq D_r \leq 12$}{In this case $E_{sys} \times T_{sys} \propto
  N^{\frac{1}{3} - \frac{4}{D_r}} + N^{1-\frac{2}{D_r}} \propto
N^{1-\frac{2}{D_r}}$.}
\end{caseof}

%Considering the two relevant cases, $D_r < 3$ and $ 3 \leq D_r \leq 12$:
%\begin{enumerate}
%\item Case I,  $D_r < 3$: Eq. \ref{`w}  $\propto N^{\frac{2}{D_r}-1} +
%  N^{\frac{-2}{D_r}}$
%\item Case II, $ 3 \leq D_r \leq 12$: Eq. \ref{eq:bio-min} $\propto N^{\frac{2}{D_r}}
%  + N^{\frac{-2}{D_r}}$
%\end{enumerate}

%Considering Case I, when $2 \leq D_r \leq 3$, both terms of
%Eq. \ref{eq:bio-min} have negative exponents and is minimized as $D_r$
%approaches 3.  Case II can never have negative exponents for both
%terms, so Case I always has a lower energy-time product, and therefre,
%Eq. \ref{eq:bio-min} is minimized as $D_r$ approaches 3.   
%therefore, the minimium of Eq. \ref{eq:min-bio} is upper
%bounded by $D_r  = 3$.  [NOTE: consider including the explicit case when
%$D_r = 3$ (on the board).
In both cases the energy time product is dominated by the second term, namely
$E_{node} \times T_{sys}$, and is minimized by $D_r =2$. [BE: Someone is going
to have to check the rest of this]
This derivation provides a straightforward theoretical explanation for why $D_r =
3$ in the lower region of the network by balancing the advantage of
distributing resources quickly against the energy cost of delivering
them.  This provides an alterative explanation for why blood slows
as it passes through the network, independently of any delivery
mechanism at the nodes.  [ADD A SENTENCE ABOUT THE LAST MILE AND PUT
IT IN THE DISCUSSION.]

%This result is interesting because it provides an alternative
%explanation for area increasing branching in the circulatory system.

% Combining terms,
% eachARE  minimized by minimizing $D_r$.  However, $N^{-1}$  is a lower bound on $R$ because when the summation is minimized, $\lambda^{-H} \propto N^{-1}$ dominates, and there is no additional benefit 
% %(for the time-energy product) 
% for $D_r < 2$.
% %Because $D_l$ is 3, the series converges to a minimum constant value when $D_r <  3$  giving
% %$R \propto \lambda^{-H} \propto N^{-1}$.  
The final energy and time scaling relations for 
organisms are  (NOTE:  putting these here to keep track for now, and noting that they don't make any sense!):

$E_{net} \propto RQ$ where R is Eq. 6,  $Q \propto N^{2/D_r}$ under the minimization condition that $D_r = 3$.
Substituting into Eq 6 gives: $R \propto N^{(-1/2)} N^{-1} N^{(1/2 - 4/3 + 1)} \propto N^{-4/3}$ and

$E_{net} \propto N^{-4/3} N^{2/3} \propto N^{-2/3} $

$E_{node} \propto N$ %(by reference to WBE)

$T_{net} \propto 1/Q \propto N^{-\frac{2}{D_r}}$ where $D_r = 2$ in the upper pulsatile area preserving part of the network so $T_{net} \propto N^{0} $ and $D_r = 3$ in the lower Poiseuillle area increasing part of the network so $T_{net} \propto N^{1/3}$.

$T_{node} \propto N^{1-2/D_r}$ matching $T_{net}$. 

%in Table \ref{tab:equations}. 


\subsection{Computers}
\label{sec:computers}

We now apply the same reasoning to computer chips. 
%The energy and time relations above are valid if transistor size is 
%kept constant as the system scales. In real systems, 
In computers, unlike biology, the nodes (transistors) 
%caling of 
%transistor count is driven by reduction in feature sizes, 
are not of constant size and have shrunk by many orders of magnitude over
40 years of micro architecture evolution.  During this time,
chip area has grown much more slowly; we assume chip area to be constant for our calculations.
Putting these two constraints together, the linear 
dimensions of transistors and wires decrease with transistor count as 
$N^{-1/2}$ (or, more generally, $N^{-1/D_l}$) \cite{moses08}.  This 
miniaturization process is well understood and is accurately modeled 
by Dennard's scaling theory \cite{dennard74}.  
%[TODO: Review Dennard scaling]  
%The final energy and 
%time formulas with the correction for technology scaling are shown in 
%Table \ref{tab:equations}.
Thus, $r_0 \propto l_0 \propto N^{-1/D_l}$. Intuitively, this means that the number of nodes increases by placing smaller transistors closer together and connecting them with smaller and shorter wires.

In the following, 
we assume that all wires carry the same flow and that information is 
transferred synchronously. We first calculate how $E_{net}$ scales with $N$. From basic principles of electronics, the 
energy dissipated to transmit a bit over a wire is given by the 
formula $CV^2/2$, where $C$ is capacitance and $V$ is voltage.  
Although energy depends on $V^2$, voltage has remained approximately 
constant over the last four decades (decreasing only by a factor of 
five while transistor count increased by six orders of magnitude 
\cite{ning07}), so we estimate that the total energy to transmit all bits over the network scales as $C$ 
\cite{bingham08}.  Ignoring fringe effects and for an aspect ratio of 
1, wire capacitance is $C_i = \epsilon l_i$ \cite{wilhelm95}, where 
$\epsilon$ is the dielectric constant.  The network capacitance is the 
sum of the capacitances of all wires, which is proportional to the 
total wire length of the network \cite{donath79}:
\begin{equation}
C \propto Length \propto  \sum_{i=0}^H l_i w_i n_i \propto
 l_0 w_0 \lambda^H \sum_{i=0}^H \lambda^{i \left( 
\frac{1}{D_l} + \frac{1}{D_w} -1 \right)}
\end{equation}

%\begin{equation}
%C = \epsilon\cdot Length = \epsilon \sum_{i=0}^H l_i w_i n_i = 
%\epsilon l_0 w_0 \lambda^H \sum_{i=0}^H \lambda^{i \left( 
%\frac{1}{D_l} + \frac{1}{D_w} -1 \right)}
%\end{equation}

where $l_i$ is the length of wire, $w_i$ is the number of wires per module, and $n_i$ is the number of modules, all at level $i$.

Recall that $l_0 \propto N^{-1/D_l}$ and $\lambda^H \propto N$ giving 

\begin{equation}
C \propto  N^{(1- 1/D_l)} \sum_{i=0}^H \lambda^{i \left( 
\frac{1}{D_l} + \frac{1}{D_w} -1 \right)}
\end{equation}

%XXXXXXX fix the leading scaling term to N to the one half, fix explanation below--it decreases with N because more local, more modular and shorter local wires.

We note that $C$, and consequently $E_{net}$, are minimized when the series converges which occurs when
$D_w >= D_l / (D_l -1)$. In this case  $C \propto \lambda^H \propto N$. The average energy to transmit a bit over the network is then given by 

\begin{equation}
E_{net} \propto C/N \propto N^{-1/D_l} 
\end{equation}

indicating that $E_{net}$ decreases with the number of terminal units in the network. This makes sense intuitively because we assume chip area is constant, so that as $N$ increases the distance between nodes is reduced. Additionally, Rent's rule, reflected in $D_w$, means that most bits move locally so that the distance distance between nearest nodes affects the average distance that bits are transmitted. 

(Not sure if this is necessary): Note that if $D_w$ were smaller than $D_l / (D_l -1)$ then energy per bit would increase with $N$, and if $D_w$ were larger than $D_l / (D_l -1)$ there would be no further reduction in the scaling of $E_{net}$. Because $D_w$ is not a factor in any other term of the energy time product, we set $D_w = D_l / (D_l -1)$, and given a 2 dimensional chip, $D_w = D_l = 2$.


%Because $E_{net}$ is defined as the energy required to transmit a bit to a single node, we need only sum over a single wire for each hierarchical level in the network, so the $n_i$ term drops
%out:
%Because energy is proportional to $C$, we focus on the region where 
%capacitance is minimized and the series converges, such that $D_w 
%> D_l/(D_l-1)$, resulting in $C \propto \lambda^H=N$. The average 
%energy to transmit a bit over the network is then given by $E_{net} 
%=CV^2/2N \propto N^0$.
%\begin{equation}
%C = \epsilon l_0 w_0 \sum_{i=0}^H \lambda^{i \left( 
%\frac{1}{D_l} + \frac{1}{D_w} \right)} \propto l_0 w_0 \frac{\lambda^{(\frac{1}{D_l} + \frac{1}{D_w}) (H + 1)} - 1}{\lambda^{(\frac{1}{D_l} + \frac{1}{D_w})} - 1} \propto N^{-1/D_l}N^{(\frac{1}{D_l} + \frac{1}{D_w})}\propto N^{1/D_w}
%\end{equation}
%\noindent where $N = \lambda^H$.
% Drop -1 from exponent and lambda^H because it was there to count up the n's which we have dropped.


We now calculate how $T_{net}$, the time to transmit a bit over a wire scales with $N$.  $T_{net}$ is equivalent to the wire latency which is 
$L \propto RC$, where $R$ is the wire resistance.  For wires with 
aspect ratio 1, $R_i = \rho l_i /r_i^2$, where $\rho$ is the 
resistivity of the material.  Thus,
\begin{equation}
L_i \propto R_i C_i = \rho \epsilon \frac{l_i^2}{r_i^2} = \rho 
\epsilon\frac{ l_0^2}{r_0^2}\lambda^{i\left( \frac{2}{D_l} 
- \frac{2}{D_r}\right)},
\end{equation}.

%where $D_r \geq D_l$, since the length of a wire cannot grow more 
%slowly than its thickness.  
Because flow is synchronous (meaning each wire transfers one bit in parallel on each clock tick), the network 
must wait until all wires have finished their transmission before 
initiating the next cycle. Therefore, the time to transfer a bit 
equals the latency of the slowest wires. We consider 3 cases.

i)  $D_r > D_l$ and latency is greatest at the highest hierarchical level, thus

\begin{equation}
\label{eq:TnetEqComp}
T_{net} = L_H \propto \frac{l_0^2}{r_0^2} \lambda^{H\left( \frac{2}{D_l} - 
\frac{2}{D_r}\right)} = N^{\left( \frac{2}{D_l} - 
\frac{2}{D_r}\right)}.
\end{equation}
In this case, because $D_r > D_l$ the exponent in Eqn. \ref{eq:TnetEqComp} is positive, and $T_{net}$ increases with $N$.

ii) In the case where $D_r < D_l$, the thickness of the wire increases faster than the length at increasing
hierarchical levels of the network.  Thus, the fastest wires would be at the highest level
of the network, and latency would be dominated by wires at the lowest level: $T_{net} = L_0 \propto \frac{l_0^2}{r_0^2} \propto N^0$.  
%In the case where
%$D_r > D_l$, the slowest wires are at the highest level of the network and the equation
%reduces to $ N^{\left( \frac{2}{D_l} - \frac{2}{D_r}\right)}$.  

iii) In the case where $D_r = D_l$, the network has perfect pipelining and the latency
is the same at every level of the network: $T_{net} =L \propto \frac{l_0^2}{r_0^2} \propto N^0$.

Of these cases, $T_{net}$ is minimized when $D_l >= D_r$,  and since $D_r$ does not affect any of the other terms in the energy-time product (Table \ref{tab:equations}),  we assume this case giving $T_{sys} \propto N_0$.  Thus, network latency, or $E_{net}$ the time for each subsequent bit to be processed by the network is independent of the number of transistors in the network.


%NOTE: change Eq 10 to the perfect pipelining case where supply = demand at each level of the network. Make the other 2 cases parentheticals in the text.

We now calculate the scaling of $E_{node}$ and $T_{node}$. For a single node, computation energy is given by the transistor's 
(dynamic) energy dissipation as $CV^2/2$.  Given that transistor size scales as $N^{-1/D_l}$,
$E_{node} \propto  N^{-1/D_l}$. % [GEORGE, PLEASE GIVE A REFERENCE AND ONE SENTENCE OF RATIONALE.]
Computation time is given by the 
transistor delay as $CV/I$ \cite{bakoglu90}, which also scales as $N^{-1/D_l}$.  %[GEORGE: ALSO NEED REFERENCE AND RATIONALE FOR THIS STMT.]
Thus, $T_{node} \propto  N^{-1/D_l}$.  

Summarizing the scaling relationships: 

$E_{net} \propto N^{-1/D_l}$

$E_{node} \propto N^{-1/D_l}$

$T_{net} \propto N^0$

$T_{node} \propto N^{-1/D_l}$



Thus, for 2 dimensional chips in which $D_l = 2$, three components of the energy time product ($E_{net}$, $E_{node}$, and $T_{node}$) scale sub linearly as $N^{-1/2}$ but $T_{net}$ is constant with respect to $N$.


Putting it all together, 

$E_{sys} = E_{net} + E_{node} \propto N^{-1/D_l} \propto N^{-1/2}$ 

$T_{sys}  = max(T_{net}, T_{node}) \propto N^0$.


%\subsection{Fitness Functions of Design}
%
%
%Recall that we express the system's energy is given as $E_{sys} = E_{net} + E_{node}$, 
%and the system's time as $T_{sys} = T_{net} + T_{node}$.  For 
%organisms, we write:
%
%\begin{equation}
%\begin{cases}
%\text{{\bf Minimize:}}\\
%\text{\;\;\;} E_{sys}\times T_{sys} (D_l, D_r) \propto \left( 
%N^{\frac{2}{D_r}-1} + N^0 \right) \times \left( N^{1 
%- \frac{2}{D_r}}+ N^{1 
%- \frac{2}{D_r}}\right)\\
%\,\\
%\text{{\bf Subject to:}}\\
%\text{\;\;\;} D_l = 3\text{ and } 2\leq D_r < \frac{4D_l}{1 + D_l}
%\end{cases}
%\label{eq:organism}
%\end{equation}\\
%
%and for computers:
%\begin{equation}
%\begin{cases}
%\text{{\bf Minimize:}}\\
%\text{\;\;\;} E_{sys}\times T_{sys} (D_l, D_r, D_w) \propto \left( N^{
%- \frac{1}{D_l}} + N^{- \frac{1}{D_l}}\right) \times \left( 
%  N^{\frac{2}{D_l} -\frac{2}{D_r}}  + N^{ - \frac{1}{D_l}}\right)\\
%\,\\
%\text{{\bf Subject to:}}\\
%\text{\;\;\;} D_l=2 \text{, } D_r \geq D_l \text{, and } D_w > 
%\frac{D_l}{D_l-1}.
%\end{cases}
%\label{eq:computer}
%\end{equation}\\

\section{Results and Discussion}
\label{sec:discussion}

The following 2 biology paragraphs need a total rewrite!!
 
Analysis of Equation \ref{eq:organism} determines the optimal value of 
$D_r$ for organisms. Although energy dissipated by the network 
decreases as $D_r$ increases, we observe that for $D_r\geq 2$ the 
energy consumed by the nodes ($N^0$) dominates the energy dissipated 
by the network ($N^{2/D_r - 1}$).  Therefore, there is no additional 
benefit to setting $D_r>2$.  On the other hand, time is reduced by 
decreasing $D_r$ and, therefore, the minimum energy-time product 
occurs at $D_r = 2$.  This result shows that the optimal network 
design is area preserving, i.e., when the aggregate cross-sectional 
area of pipes is the same at all hierarchical levels. Various 
derivations show that this design leads to the 3/4 power scaling of 
metabolic rate known as Kleiber's law (e.g., \cite{west97, 
banavar10}).

The model predicts that, for the optimal network design (i.e., $D_l=3$  
and $D_r=2$), the system's energy-time product is invariant with 
respect to $N$.  Since size increases with $N$, this suggests that the 
energy-time product is independent of body mass.   This result has 
important implications for the energetic basis of fitness.  Some have 
proposed that biological fitness maximizes metabolic power 
(energy/time) \cite{lotka56, odum71}, whereas others have proposed 
that it minimizes biological times (e.g., generation times, which is 
equivalent to maximizing vital rates) \cite{lindstedt81, sibly91}. The 
invariance of the energy-time product is consistent with the fact that 
fitness of organisms is largely independent of body mass.  Organisms 
of all sizes, from small, fast, low-power microbes to large, slow, 
powerful mammals, coexist and, therefore, are likely nearly equally 
fit.  This implies a direct trade-off between maximizing metabolic 
power and minimizing generation times that holds over the many orders 
of magnitude variation in body mass.  The energy-time product reflects 
powerful geometric, physical and biological constraints on the 
evolution of organism designs.

For computers, minimizing the energy time product is trivial: 
also leading to $D_l=D_r=D_w = 2$,.  This result corresponds to ideal scaling, as 
suggested by Dennard \cite{dennard74}, where the linear dimensions of 
transistors and wires scale at the same rate, and wire delay is 
constant and the Rent's exponent is 1/2, consistent with observations (NEED citations.)

From this result, we make two important predictions.  First, power consumption in chips (total energy dissipated per 
unit of time) scales as $Power = (N\cdot E_{sys})/T_{sys} \propto 
N^{1/2}$.  Performance is given by the  number of computations 
executed per unit of time, or throughput.  Second, assuming that a constant 
fraction of the transistors is active at each cycle, throughput is 
predicted to scale linearly with $N$,  i.e.  $Throughput\propto 
N/T_{sys} \propto N$.


We compared the predictions for power consumption with data obtained 
for 523 different microprocessors over a range of approximately 6 
orders of magnitude in transistor count.  The data are shown in Figure 
\ref{fig:power}, where the measured exponent was $0.495$, which agrees 
closely with the prediction of $0.5$. Consistent data on performance 
across many technology generations is difficult to obtain because the 
standards have changed over the years and their adoption by different 
vendors is not uniform.  We were able to obtain normalized performance 
data for 16 Intel processors from different generations over a range 
of 6 orders of magnitude in transistor count.  The exponent obtained 
for these data was $1.0$, as shown in Figure \ref{fig:throughput}, 
which agrees exactly with the predictions from our analysis. This 
suggests that engineered designs approach the theoretical optimal 
defined by the model.  The final energy-time product predicted by the 
model scales as $N^{-1/2}$, showing that, unlike organisms, as size 
increases, the energy-delay product decreases systematically. This is 
a consequence of process technology improvement, since newer, larger 
processors use hardware that is smaller, faster and more energy efficient.


\begin{figure}[!h]
\centering
\includegraphics[height=70mm]{Figures/power_scaling.pdf}
\caption{ }
\label{fig:power}
\end{figure}

\begin{figure}[!h]
\centering
\includegraphics[height=70mm]{Figures/throughput_scaling.pdf}
\caption{ }
\label{fig:throughput}
\end{figure}

Our model provides a simple theoretical explanation for the scaling of 
power and performance in computers over 40 years of microprocessor 
technology improvements.  The excellent agreement between the 
theoretical optimal and experimental data suggests that through 
successive generations of trial-and-error, innovation and 
optimization, engineered designs are highly successful, approaching 
the theoretical limit predicted by the model.

These results also provide an explanation for Koomey's Law, which states roughly: ``The number of computations per joule of energy dissipated has been doubling approximately every 1.57 years." This follows directly from minimizing the energy time product and Moore's Law, the empirical observation that the number of transistors ($N$) doubles every 2 years. NEED a figure that combines data from Fig 2 and Fig 3 to show this?

\section{Discussion}

\begin{itemize}
\item By unifying time and energy into a single model, the model
  accounts for the wide variation in size of organisms and computers,
  e.g., mouse to elephant and arm to multe-core.

\item We provide an explanation for Koomey's Law (p. 13)

\item The model shows why computers have given up on reducing clock
  speeds and gone to multi-core.  Once you reach a minimum component
  size, then you are at a transition and a new scaling regime.  What
  is the regime and why is biology the guide?

\item The joule-second as a new fundamental unit of life and
  information.

\item Theoretical explanation for well-known empirical patterns in
  computer architecture.

\item Nature dealt with network design constraints by slowing
  metabolism as animal size increases.  Computer architecture, at
  least until recently, focused on increase clock speeds by minimizing
  component size and incresing energy per chip.  Also, using the third dimension to accommodate more wires, 

\item Computer transions: transistors; transistors to
  integrated circuits; single core to multi-core; desk tops to data centers.
Multicore is an evolutionary transition.  IBM currently making 10 nm chips which are the limit for
  silicon.  IBM recently announced a 7 nm
transistor (more than 1000 times smaller than the diameter of a red
blood cell) and only three times larger than a strand of DNS, using
silicon germanium targeting a 50\% power improvement.  NYT July 9,
2015.  Then going to carbon nanofibers. 

\end{itemize}

\section{Conclusion}

Our analysis provides a unifying explanation for the origin of scaling 
laws in biology and computing. Despite obvious differences in form and 
function, the scaling of organisms and computers is governed by the 
same simple principle.  By minimizing the energy-time product, whether 
through natural selection or engineering, existing designs manage the 
trade-off between cost and performance, leading to general scaling 
patterns observed over several orders of magnitude in size.  Moreover, 
power laws as a function of size are not unique to organisms and 
computers but are widely observed across a large variety of complex 
systems in nature, society and technology.  The scaling of white and 
grey matter in the brain \cite{zhang00}, of energy use and GDP in 
countries \cite{brown11}, and the pace of life and population in 
cities \cite{bettencourt07} are additional examples where a unifying 
explanation is still lacking.  Because cost and performance, i.e., 
energy and time, impose universal constraints, we suggest that a 
common design principle governs the scaling of complex systems that 
process energy, materials and information.


\section{Appendix A: Resistance Scaling in Organisms}
\label{sec:AppendixOrg}

In this section we give a detailed analysis of the derivation of the scaling of
the total network resistance discussed in Sec.~\ref{sec:organisms}. Recall
that $D_l = 3$ for $3$ dimensional organisms and that $\lambda^{-H}=N^{-1}$.
Using these values and simplifying, equation~\ref{eq:resistance} is
transformed. 

\begin{equation}
 R = \frac{8 \mu l_0}{\pi r_0^4} N^{-1} \sum_{i=0}^H \lambda^{i(\frac{4}{3} -\frac{4}{D_r})}
\end{equation}

Let the summand $S = \sum_{i=0}^H \lambda^{i(\frac{4}{3} -\frac{4}{D_r})}$. $R \propto
N^{-1} S$. How $S$ scales with $N$ is dependent on the exponent $\frac{4}{3} -
\frac{4}{D_r}$, and reduces to four different cases:

\begin{caseof}

    \case{$D_r=3$}{In this case the exponent is equal to 0, and the $S = H+1
    \propto \log (N)$, and $R\propto \frac{\log(N)}{N}$, because $\log(N)$ in
  this case grows much more slowly than $N$, it is reasonable to conclude that
$R\propto N^{-1}$}

    \case{$D_r < 3$}{Here (and in subsequent cases) we can use the geometric series to
      calculate the exact value of $S$. In particular 

      \begin{align*}
        S &= \frac{(1-\lambda^{(\frac{4}{3}
    -\frac{4}{D_r})(H+1)})}{1-\lambda^{\frac{4}{3} -\frac{4}{D_r}}} \\ 
        &= \frac{1-\left(\lambda^{H}\right)^{(\frac{4}{3}-\frac{4}{D_r})}
      \lambda^{(\frac{4}{3} - \frac{4}{D_r}))}}{1-\lambda^{\frac{4}{3}
      -\frac{4}{D_r}}} \\
        &= \frac{1-N^{(\frac{4}{3}-\frac{4}{D_r})}
      \lambda^{(\frac{4}{3} - \frac{4}{D_r}))}}{1-\lambda^{\frac{4}{3}
           -\frac{4}{D_r}}}
      \end{align*}

      If we let $c = \lambda^{(\frac{4}{3} -\frac{4}{D_r})}$ we see that

      \begin{equation}
        S = \frac{1-c N^{(\frac{4}{3}-\frac{4}{D_r})}}{1-c}
      \end{equation}

      Because $\frac{4}{3} - \frac{4}{D_r} < 0$ is negative in this case
      and $N$ is large in practice, $c N^{(\frac{4}{3} -\frac{4}{D_r})}$ is
      small, and $S$ is proportional to a constant ($S \approx
    \frac{1}{1-c}$). This implies that $R \propto N^{-1}$.}

    \case{$3 < D_r < 12 $}{In this case the exponent in $S$ is positive,
      meaning that $S$ scales directly with $N$. Note that $c>1$ in this case
      and we can write 
      \begin{equation}
        S = \frac{c N^{(\frac{4}{3}-\frac{4}{D_r})}-1}{c-1}
      \end{equation}

      \noindent This means that $S \propto N^{(\frac{4}{3} - \frac{4}{D_r})}$.
      This implies that $R \propto N^{-1} S \propto N^{(\frac{1}{3}
      -\frac{4}{D_r})}$. This means that resistance still scales inversely with
      size, but at a faster rate than if $D_r \leq 3$.}

   \case{$D_r \geq 12$}{This final case is analogous to the one above, except
   that now resistance scales positively with $N$, implying that the energy in
 the network would scale positively with $N$. This is likely a non-physical
 possibility, but we include it here for completeness.}

\end{caseof}

\bibliography{references}
\bibliographystyle{abbrv}

\newpage

\section*{Figure legends}
\paragraph{Figure 1:} Log-log plot of power consumption as a function 
of transistor count for 523 computer microprocessors from different 
vendors and technological generations.  The linear regression slope is 
$0.495$ with correlation coefficient of $0.81$. A regression that 
removes the first seven data points and focuses on the main cloud of 
more modern chips produces a slope of $0.487$.

\paragraph{Figure 2:} Log-log plot of normalized throughput as a 
function of transistor count for 16 Intel microprocessors from 
different technological generations.  The linear regression slope is 
1.0 with correlation coefficient of 0.97.

\end{document}



